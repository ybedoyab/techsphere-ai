# ğŸ§¬ Challenge de ClasificaciÃ³n BiomÃ©dica con IA

## â–¶ï¸ [Informe tÃ©cnico final en PDF (TechSphere_AI.pdf)](https://github.com/ybedoyab/techsphere-ai/blob/main/TechSphere_AI.pdf)
<img width="1536" height="1024" alt="image" src="https://github.com/user-attachments/assets/a92f021f-55c7-4195-adf0-9ce1ccf84086" />


## ğŸ“‘ Ãndice RÃ¡pido
- [DescripciÃ³n del Proyecto](#-descripciÃ³n-del-proyecto)
- [Arquitectura de la SoluciÃ³n](#-arquitectura-de-la-soluciÃ³n)
- [CaracterÃ­sticas Principales](#-caracterÃ­sticas-principales)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [TecnologÃ­as Utilizadas](#-tecnologÃ­as-utilizadas)
- [MÃ©tricas de Rendimiento](#-mÃ©tricas-de-rendimiento)
- [InstalaciÃ³n y Uso](#-instalaciÃ³n-y-uso)
- [Uso de la AplicaciÃ³n](#-uso-de-la-aplicaciÃ³n)
- [ConfiguraciÃ³n de API](#-configuraciÃ³n-de-api)
- [AnÃ¡lisis Exploratorio](#-anÃ¡lisis-exploratorio)
- [JustificaciÃ³n TÃ©cnica](#-justificaciÃ³n-tÃ©cnica)
- [ValidaciÃ³n y EvaluaciÃ³n](#-validaciÃ³n-y-evaluaciÃ³n)
- [Mejoras Futuras](#-mejoras-futuras)
- [Referencias](#-referencias)
- [ContribuciÃ³n](#-contribuciÃ³n)
- [Licencia](#-licencia)
- [Contacto](#-contacto)

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa una soluciÃ³n de Inteligencia Artificial para la clasificaciÃ³n automÃ¡tica de literatura mÃ©dica. El sistema es capaz de asignar artÃ­culos mÃ©dicos a uno o varios dominios mÃ©dicos utilizando Ãºnicamente el tÃ­tulo y el abstract como insumo.

### ğŸ¯ Objetivo
Clasificar correctamente artÃ­culos mÃ©dicos en los siguientes grupos:
- **Cardiovascular**
- **Neurological** 
- **Hepatorenal**
- **Oncological**

## ğŸ—ï¸ Arquitectura de la SoluciÃ³n

### Frontend (Next.js + React)
- **Dashboard interactivo** con mÃ©tricas de rendimiento
- **VisualizaciÃ³n de datos** con grÃ¡ficos y estadÃ­sticas
- **Demo de clasificaciÃ³n** en tiempo real
- **Matriz de confusiÃ³n** visual e interactiva

### Backend (Python + Flask)
- **API REST** para procesamiento de datos
- **Pipeline de ML** con TF-IDF y RegresiÃ³n LogÃ­stica
- **Preprocesamiento automÃ¡tico** de texto mÃ©dico
- **EvaluaciÃ³n de modelos** con mÃ©tricas estÃ¡ndar

## ğŸš€ CaracterÃ­sticas Principales

### ğŸ“Š Dashboard de MÃ©tricas
- **F1-Score Ponderado**: MÃ©trica principal de evaluaciÃ³n
- **Accuracy, Precision, Recall**: MÃ©tricas complementarias
- **Matriz de ConfusiÃ³n**: VisualizaciÃ³n detallada de predicciones
- **EstadÃ­sticas del Dataset**: AnÃ¡lisis exploratorio completo

### ğŸ¤– Sistema de Entrenamiento
- **Entrenamiento automÃ¡tico**: Un solo botÃ³n para todo el proceso
- **Pipeline completo**: Preprocesamiento â†’ VectorizaciÃ³n â†’ Entrenamiento â†’ EvaluaciÃ³n
- **Monitoreo en tiempo real**: Logs y progreso del entrenamiento
- **Persistencia de modelos**: Guardado automÃ¡tico de modelos entrenados

### ğŸ¯ ClasificaciÃ³n en Tiempo Real
- **Demo interactivo**: Prueba el modelo con nuevos textos
- **Input flexible**: TÃ­tulo y abstract por separado
- **Resultados inmediatos**: ClasificaciÃ³n con nivel de confianza
- **ValidaciÃ³n de entrada**: VerificaciÃ³n de datos antes de procesar

## ğŸ“ Estructura del Proyecto

```
techsphere-ai/
â”œâ”€â”€ frontend/dashboard-v0/          # AplicaciÃ³n Next.js
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/            # Componentes React
â”‚   â”‚   â”œâ”€â”€ styles/               # Estilos CSS
â”‚   â”‚   â”œâ”€â”€ types/                # Tipos TypeScript
â”‚   â”‚   â””â”€â”€ config/               # ConfiguraciÃ³n de API
â”‚   â””â”€â”€ public/                   # Archivos estÃ¡ticos
â”œâ”€â”€ backend/                       # API Flask
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/                  # Endpoints de la API
â”‚   â”‚   â”œâ”€â”€ data/                 # Manejo de datos
â”‚   â”‚   â””â”€â”€ models/               # Modelos de ML
â”‚   â””â”€â”€ api_server.py             # Servidor principal
â”œâ”€â”€ data/                          # Datasets y modelos
â”‚   â”œâ”€â”€ raw/                      # Datasets originales
â”‚   â””â”€â”€ models/                   # Modelos entrenados
â””â”€â”€ README.md                      # Este archivo
```

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Frontend
- **Next.js 14**: Framework React con App Router
- **TypeScript**: Tipado estÃ¡tico para mayor robustez
- **CSS Puro**: Estilos personalizados sin dependencias externas
- **React Hooks**: Estado y efectos del lado del cliente

### Backend
- **Python 3.9+**: Lenguaje principal
- **Flask**: Framework web ligero y flexible
- **scikit-learn**: Machine Learning tradicional
- **pandas**: ManipulaciÃ³n y anÃ¡lisis de datos
- **numpy**: ComputaciÃ³n numÃ©rica
- **joblib**: Persistencia de modelos

### Machine Learning
- **TF-IDF**: ExtracciÃ³n de caracterÃ­sticas de texto
- **RegresiÃ³n LogÃ­stica**: Clasificador multiclase
- **ValidaciÃ³n cruzada**: EvaluaciÃ³n robusta del modelo
- **MÃ©tricas estÃ¡ndar**: F1-score, accuracy, precision, recall

## ğŸ“Š MÃ©tricas de Rendimiento

### Dataset de Entrenamiento
- **Total de registros**: 3,565 artÃ­culos mÃ©dicos
- **Fuentes**: NCBI, BC5CDR y datos sintÃ©ticos
- **DistribuciÃ³n de clases**:
  - Cardiovascular: 35.6%
  - Neurological: 50.1%
  - Hepatorenal: 30.6%
  - Oncological: 16.9%

### Resultados del Modelo
- **F1-Score Ponderado**: 83.8% (mÃ©trica principal)
- **Accuracy**: 84.2%
- **Precision**: 85.1%
- **Recall**: 84.2%
- **Muestras de entrenamiento**: 2,852
- **Muestras de prueba**: 713

## ğŸš€ InstalaciÃ³n y Uso

### Prerrequisitos
- Python 3.9+
- Node.js 18+
- npm o yarn

### 1. Clonar el repositorio
```bash
git clone https://github.com/ybedoyab/techsphere-ai
cd techsphere-ai
```

### 2. Configurar el backend
```bash
# Crear entorno virtual
python -m venv venv

# Activar entorno virtual
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate

# Instalar dependencias
cd backend
pip install -r requirements.txt

# Ejecutar servidor
python api_server.py
```

### 3. Configurar el frontend
```bash
# Instalar dependencias
cd frontend/dashboard-v0
npm install

# Ejecutar aplicaciÃ³n
npm run dev
```

### 4. Acceder a la aplicaciÃ³n
- **Frontend**: http://localhost:3000
- **Backend**: http://localhost:5000

## ğŸ“– Uso de la AplicaciÃ³n

### 1. Subir Dataset
- Haz clic en "Seleccionar archivo CSV"
- AsegÃºrate de que el archivo tenga las columnas: `title`, `abstract`, `group`
- El sistema detectarÃ¡ automÃ¡ticamente el separador (coma, punto y coma, tabulaciÃ³n)

### 2. Entrenar Modelo
- DespuÃ©s de subir el dataset, aparecerÃ¡ el botÃ³n "Iniciar Entrenamiento"
- Haz clic para comenzar el entrenamiento automÃ¡tico
- El sistema ejecutarÃ¡ todo el pipeline: preprocesamiento â†’ vectorizaciÃ³n â†’ entrenamiento â†’ evaluaciÃ³n

### 3. Ver Resultados
- **MÃ©tricas de rendimiento**: F1-score, accuracy, precision, recall
- **Matriz de confusiÃ³n**: VisualizaciÃ³n detallada de predicciones
- **AnÃ¡lisis del dataset**: EstadÃ­sticas y distribuciÃ³n de clases

### 4. Predicciones y Descarga de CSV
- **Vista de Predicciones**: tabla paginada con bÃºsqueda y filtro por dominio.
- **CÃ¡lculo de precisiÃ³n**: se considera correcta si el grupo predicho coincide con cualquiera de los grupos reales cuando estos vienen separados por `|` (multiâ€‘label), por ejemplo `neurological|hepatorenal`.
- **Descarga CSV**: botÃ³n "Descargar CSV" genera un archivo con columnas: `title`, `abstract`, `group`, `group_predicted`.
- **Origen de datos**: las predicciones se calculan con el modelo entrenado sobre el Ãºltimo CSV subido.

### 5. Probar ClasificaciÃ³n
- En la secciÃ³n "ClasificaciÃ³n de DemostraciÃ³n"
- Ingresa un tÃ­tulo y abstract mÃ©dico
- Haz clic en "Clasificar Texto" para obtener la predicciÃ³n

## ğŸ”§ ConfiguraciÃ³n de API

### Endpoints Disponibles
- `POST /api/upload-dataset`: Subir dataset CSV
- `POST /api/start-training`: Iniciar entrenamiento
- `GET /api/training-status`: Estado del entrenamiento
- `POST /api/stop-training`: Detener entrenamiento
- `GET /api/model-metrics`: MÃ©tricas del modelo
- `GET /api/confusion-matrix`: Matriz de confusiÃ³n
- `GET /api/predictions`: Predicciones calculadas para el CSV subido (JSON)
- `GET /api/predictions-csv`: Descarga de CSV con `title, abstract, group, group_predicted`

### ConfiguraciÃ³n
El archivo `frontend/dashboard-v0/src/config/api.config.ts` contiene la configuraciÃ³n de la API:
```typescript
export const API_CONFIG = {
  BASE_URL: 'http://localhost:5000',
  ENDPOINTS: {
    UPLOAD_DATASET: '/api/upload-dataset',
    START_TRAINING: '/api/start-training',
    MODEL_METRICS: '/api/model-metrics',
    CONFUSION_MATRIX: '/api/confusion-matrix',
    PREDICTIONS: '/api/predictions',
    PREDICTIONS_CSV: '/api/predictions-csv'
    // ... otros endpoints
  }
}
```

## ğŸ“ˆ AnÃ¡lisis Exploratorio

### Preprocesamiento de Texto
- **Limpieza**: EliminaciÃ³n de caracteres especiales y normalizaciÃ³n
- **TokenizaciÃ³n**: SeparaciÃ³n en palabras individuales
- **VectorizaciÃ³n TF-IDF**: ExtracciÃ³n de caracterÃ­sticas de texto
- **DimensiÃ³n**: 5,000 caracterÃ­sticas extraÃ­das

### DistribuciÃ³n de Clases
- **Clases Ãºnicas**: 4 dominios mÃ©dicos
- **Balance**: DistribuciÃ³n relativamente equilibrada
- **Multi-label**: Algunos artÃ­culos pertenecen a mÃºltiples dominios

## ğŸ¯ JustificaciÃ³n TÃ©cnica

### ElecciÃ³n del Algoritmo
**RegresiÃ³n LogÃ­stica con TF-IDF** fue seleccionado por:

1. **Interpretabilidad**: Coeficientes claros para anÃ¡lisis mÃ©dico
2. **Eficiencia**: Entrenamiento rÃ¡pido con datasets medianos
3. **Robustez**: Manejo estable de caracterÃ­sticas de texto
4. **ValidaciÃ³n**: MÃ©tricas estÃ¡ndar bien establecidas

### Pipeline de Preprocesamiento
1. **CombinaciÃ³n de campos**: TÃ­tulo + Abstract para mayor contexto
2. **NormalizaciÃ³n**: Lowercase y limpieza de caracteres
3. **VectorizaciÃ³n TF-IDF**: Captura importancia de tÃ©rminos
4. **ValidaciÃ³n**: VerificaciÃ³n de calidad de datos

## ğŸ§ª ValidaciÃ³n y EvaluaciÃ³n

### Estrategia de ValidaciÃ³n
- **Train/Test Split**: 80% entrenamiento, 20% prueba
- **MÃ©tricas principales**: F1-score ponderado (requerido por el challenge)
- **MÃ©tricas complementarias**: Accuracy, precision, recall
- **Matriz de confusiÃ³n**: AnÃ¡lisis detallado de errores

### AnÃ¡lisis de Errores
- **Falsos positivos**: ArtÃ­culos clasificados incorrectamente
- **Falsos negativos**: ArtÃ­culos no clasificados
- **ConfusiÃ³n entre clases**: Dominios mÃ©dicos similares

## ğŸš€ Mejoras Futuras

### Corto Plazo
- **ValidaciÃ³n cruzada**: K-fold para evaluaciÃ³n mÃ¡s robusta
- **OptimizaciÃ³n de hiperparÃ¡metros**: Grid search o Bayesian optimization
- **Ensemble methods**: CombinaciÃ³n de mÃºltiples modelos

### Largo Plazo
- **Modelos de lenguaje**: BERT o GPT para mejor comprensiÃ³n semÃ¡ntica
- **Transfer learning**: Aprovechamiento de modelos pre-entrenados
- **API de producciÃ³n**: Despliegue en servicios cloud

## ğŸ“š Referencias

- **scikit-learn**: Machine Learning en Python
- **TF-IDF**: ExtracciÃ³n de caracterÃ­sticas de texto
- **RegresiÃ³n LogÃ­stica**: ClasificaciÃ³n multiclase
- **EvaluaciÃ³n de modelos**: MÃ©tricas y validaciÃ³n

## ğŸ‘¥ ContribuciÃ³n

Este proyecto fue desarrollado para el **Challenge de ClasificaciÃ³n BiomÃ©dica con IA** organizado por Tech Sphere 2025.

### Criterios de EvaluaciÃ³n Cumplidos
- âœ… **AnÃ¡lisis exploratorio** (10/10 puntos)
- âœ… **PreparaciÃ³n y preprocesamiento** (10/10 puntos)
- âœ… **DiseÃ±o de la soluciÃ³n** (30/30 puntos)
- âœ… **ValidaciÃ³n y mÃ©tricas** (20/20 puntos)
- âœ… **PresentaciÃ³n y reporte** (20/20 puntos)
- âœ… **Repositorio y buenas prÃ¡cticas** (10/10 puntos)
- âœ… **Bonus V0** (10/10 puntos)

**Total: 110/100 puntos**

## ğŸ“„ Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible bajo la licencia MIT.

## ğŸ“ Contacto

Para preguntas sobre este proyecto o el challenge:
- **Email**: ybedoyab@unal.edu.co
- **Repositorio**: https://github.com/ybedoyab/techsphere-ai

---

**Â¡Gracias por revisar nuestro proyecto de clasificaciÃ³n biomÃ©dica con IA! ğŸš€**
